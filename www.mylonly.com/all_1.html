<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  独自一人
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="独自一人" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:www.mylonly.com ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; 独自一人</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="ios.html">iOS</a></li>
        
            <li><a href="linux.html">Linux</a></li>
        
            <li><a href="python.html">Python</a></li>
        
            <li><a href="tools.html">Tools</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="14945011166438.html">
                
                  <h1>Scrapy——crawlSpider爬虫</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>Scrapy中的BaseSpider爬虫类只能抓取start_urls中提供的链接，而利用Scrapy提供的crawlSpider类可以很方便的自动解析网页上符合要求的链接，从而达到爬虫自动抓取的功能。<br/>
 <br/>
要利用crawSpider和BaseSpider的区别在于crawSpider提供了一组Rule对象列表，这些Rule对象规定了爬虫抓取链接的行为，Rule规定的链接才会被抓取，交给相应的callback函数去处理。<br/>
  <br/>
在rules中通过SmglLinkExtractor提取希望获取的链接。<br/>
 <br/>
我此次的demo中rule只有一个，如下：</p>

<pre><code class="language-python">allowed_domains = [&#39;sj.zol.com.cn&#39;]
start_urls = [&#39;http://sj.zol.com.cn/bizhi/&#39;]
number = 0
rules = (
            Rule(SgmlLinkExtractor(allow = (&#39;detail_\d{4}_\d{5}\.html&#39;)),callback = &#39;parse_image&#39;,follow=True),
            )
</code></pre>

<p>搜索起始链接下面符合allow中正则表达式的链接，并跟进解析，如果follow = False，则只会解析起始链接中找到的符合要求的链接<br/>
 <br/>
SmglLinkExtractor主要参数：<br/>
 <br/>
- allow：满足括号中“正则表达式”的值会被提取，如果为空，则全部匹配。<br/>
- deny：与这个正则表达式(或正则表达式列表)不匹配的URL一定不提取。<br/>
- allow_domains：会被提取的链接的domains。<br/>
- deny_domains：一定不会被提取链接的domains。<br/>
- restrict_xpaths：使用xpath表达式，和allow共同作用过滤链接。<br/>
 <br/>
下面的内容就是利用Selector解析获得的response并赋值个item就行了：</p>

<pre><code class="language-python">#coding: utf-8 #############################################################
# File Name: spiders/wallpaper.py
# Author: mylonly
# mail: tianxianggen@gmail.com
#Blog:www.mylonly.com
# Created Time: 2014年09月01日 星期一 14时20分07秒
#########################################################################
#!/usr/bin/python
import urllib2
import os
import re
 
from scrapy.contrib.spiders import CrawlSpider,Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import Selector
from mylonly.items import wallpaperItem
from scrapy.http import Request
 
class wallpaper(CrawlSpider):
        name = &quot;wallpaperSpider&quot;
        allowed_domains = [&#39;sj.zol.com.cn&#39;]
        start_urls = [&#39;http://sj.zol.com.cn/bizhi/&#39;]
        number = 0
        rules = (
                        Rule(SgmlLinkExtractor(allow = (&#39;detail_\d{4}_\d{5}\.html&#39;)),callback = &#39;parse_image&#39;,follow=True),
                        )
        def parse_image(self,response):
                self.log(&#39;hi,this is an item page! %s&#39; % response.url)
                sel = Selector(response)
                sites = sel.xpath(&quot;//div[@class=&#39;wrapper mt15&#39;]//dd[@id=&#39;tagfbl&#39;]//a[@target=&#39;_blank&#39;]/@href&quot;).extract()       
                for site in sites:
                        url = &#39;http://sj.zol.com.cn%s&#39; % (site)
                        print &#39;one page:&#39;,url
                        item = wallpaperItem()
                        item[&#39;size&#39;] = re.search(&#39;\d*x\d*&#39;,site).group()
                        item[&#39;altInfo&#39;] = sel.xpath(&quot;//h1//a/text()&quot;).extract()[0]
                        return Request(url,meta = {&#39;item&#39;:item},callback = self.parse_href)
        def parse_href(self,response):
                print &#39;I am in:&#39;,response.url
                item = response.meta[&#39;item&#39;]
                items = []
                sel = Selector(response)
                src = sel.xpath(&quot;//body//img/@src&quot;).extract()[0]
                item[&#39;imgSrc&#39;] = src
                items.append(item)
                return items
                #self.download(src)
        def download(self,url):
                self.number += 1
                savePath = &#39;/mnt/python_image/%d.jpg&#39; % (self.number)
                print &#39;正在下载...&#39;,url
                try:
                        u = urllib2.urlopen(url)
                        r = u.read()
                        downloadFile = open(savePath,&#39;wb&#39;)
                        downloadFile.write(r)
                        u.close()
                        downloadFile.close()
                except:
                        print savePath,&#39;can not download.&#39;
</code></pre>

<p> <br/>
 <br/>
 <br/>
接下来看看我的Item.py的代码：</p>

<pre><code class="language-python">class wallpaperItem(scrapy.Item):
        size = scrapy.Field()
        altInfo = scrapy.Field()
        imgSrc = scrapy.Field()
</code></pre>

<p> <br/>
还有pipilines.py:</p>

<pre><code class="language-python"># -*- coding: utf-8 -*-
 
# Define your item pipelines here
#
# Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting
# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html
import MySQLdb
 
 
class MylonlyPipeline(object):
    def process_item(self, item, spider):
        return item
 
class wallpaperPipeline(object):
        def process_item(self,item,spider):
                print &#39;imgSrc:&#39;,item[&#39;imgSrc&#39;]
                db = MySQLdb.connect(&quot;rdsauvva2auvva2.mysql.rds.aliyuncs.com&quot;,&quot;mylonly&quot;,&quot;703003659txg&quot;,&quot;wallpaper&quot;)
                cursor = db.cursor()
                db.set_character_set(&#39;utf8&#39;)
                cursor.execute(&#39;SET NAMES utf8;&#39;)
                cursor.execute(&#39;SET CHARACTER SET utf8;&#39;)
                cursor.execute(&#39;SET character_set_connection=utf8;&#39;)
 
                sql =&quot;INSERT INTO mobile_download(wallpaper_size,wallpaper_info,wallpaper_src)\
                      VALUES(&#39;%s&#39;,&#39;%s&#39;,&#39;%s&#39;)&quot;%(item[&#39;size&#39;],item[&#39;altInfo&#39;],item[&#39;imgSrc&#39;])
                try:
                        print sql
                        cursor.execute(sql)
                        db.commit()
                except MySQLdb.Error,e:
                        print &quot;Mysql Error %d: %s&quot; % (e.args[0], e.args[1])
                db.close()
                return item
</code></pre>

<p> <br/>
 <br/>
 <br/>
本例中我将传回的items数据存放到了数据库中，如果你不想这样，可以将我注释掉的self.download()取消注释，不反悔items，就可以将找到的所有图片链接全部下载下来，不过要找个大点的地方存储，因为总共有5W多条：<br/>
<img src="http://pic.mylonly.com/2016-06-29_061712481319744.png" alt="2016-06-29_061712481319744.png"/></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/5/11</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='python.html'>Python</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14945011027951.html">
                
                  <h1>Python利用Pexpect模拟ssh交互</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<blockquote>
<p><mark>关于Pexpect</mark><br/>
Pexpect 是 Don Libes 的 Expect 语言的一个 Python 实现，是一个用来启动子程序，并使用正则表达式对程序输出做出特定响应，以此实现与其自动交互的 Python 模块。 Pexpect 的使用范围很广，可以用来实现与 ssh、ftp 、telnet 等程序的自动交互；可以用来自动复制软件安装包并在不同机器自动安装；还可以用来实现软件测试中与命令行交互的自动化。</p>
</blockquote>

<h5 id="toc_0">本文利用到的Pexpect的类和方法</h5>

<ol>
<li><p><code>spawn()</code>类:</p>

<pre><code class="language-Python">class spawn:
    def __init__(self,command,args=[],timeout=30,maxread=2000,\
    searchwindowsize=None, logfile=None, cwd=None, env=None)
</code></pre>

<p>spawn是Pexpect模块主要的类，用以实现启动子程序，它有丰富的方法与子程序交互从而实现用户对子程序的控制。它主要使用 pty.fork() 生成子进程，并调用 exec() 系列函数执行 command 参数的内容。</p></li>
<li><p><code>spawn()</code>类中的<code>expect()</code>函数:</p>

<pre><code class="language-Python">expect(self, pattern, timeout=-1, searchwindowsize=None)
</code></pre>

<p>在参数中： pattern 可以是正则表达式， pexpect.EOF ， pexpect.TIMEOUT ，或者由这些元素组成的列表。需要注意的是，当 pattern 的类型是一个列表时，且子程序输出结果中不止一个被匹配成功，则匹配返回的结果是缓冲区中最先出现的那个元素，或者是列表中最左边的元素。使用 timeout 可以指定等待结果的超时时间 ，该时间以秒为单位。当超过预订时间时， expect 匹配到pexpect.TIMEOUT。</p></li>
<li><p><code>spawn()</code>类中的<code>before</code>和<code>after</code>属性:</p>

<p>expect 不断从读入缓冲区中匹配目标正则表达式，当匹配结束时 pexpect 的 before 成员中保存了缓冲区中匹配成功处之前的内容， pexpect 的 after 成员保存的是缓冲区中与目标正则表达式相匹配的内容。</p>

<pre><code class="language-Python">child = pexpect.spawn(&#39;/bin/ls /&#39;) 
child.expect (pexpect.EOF) 
print child.before
</code></pre>

<p>以上代码就是打印在根目录下面执行ls命令后的输出内容</p></li>
<li><p><code>spawn()</code>类中的send系列函数:</p>

<pre><code class="language-Python">send(self, s) 
sendline(self, s=&#39;&#39;) 
sendcontrol(self, char)
</code></pre>

<p>这些方法用来向子程序发送命令，模拟输入命令的行为。 与 send() 不同的是 sendline() 会额外输入一个回车符 ，更加适合用来模拟对子程序进行输入命令的操作。 当需要模拟发送 “Ctrl+c” 的行为时，还可以使用 sendcontrol() 发送控制字符。</p>

<pre><code class="language-Python">child.sendcontrol(&#39;c&#39;)

</code></pre></li>
</ol>

<h5 id="toc_1">功能模块分解</h5>

<ol>
<li><p>首先我们需要一个可以单独的session会话，可以由connect函数创建指定host,username和password的会话子进程</p>

<pre><code>```Python
PROMPT = [&#39;#&#39;,&#39;$&#39;,&#39;&gt;&#39;,&#39;\$&#39;,&#39;&gt;&gt;&gt;&#39;]
def createChildSession(host,username,password):
    command = &#39;ssh &#39;+username+&#39;@&#39;+host
    child = pexpect.spawn(command)
    ret = child.expect([pexpect.TIMEOUT,&#39;Are you sure you want to continue connecting&#39;,&#39;[P|p]assword&#39;]+PROMPT)
    if ret == 0:
        print(&#39;[-] Error Connecting&#39;)
        return
    if ret == 1:
        child.sendline(&#39;yes&#39;)
        ret = child.expect([pexpect.TIMEOUT,&#39;[p|P]assword&#39;])
        if ret == 0:
            print(&#39;[-] Error Connecting&#39;)
            return
        if ret == 1:
            send_command(password)
            return
    if ret == 2:
        send_command(password)
        return
    return child
```
利用spawn创建会话之后,利用expect匹配可能存在的返回结果,如果匹配&#39;Are you sure you want to continue connecting&#39; 说明需要确认认证信息，如果直接返回password或者Password`这里利用[p|P]assword正则来匹配`,说明需要输入密码,如果直接是PROMPT中存在的字符，说明直接登录上去了。
</code></pre></li>
<li><p>一个单独的执行命令的函数:</p>

<pre><code class="language-Python">def send_command(child,cmd):
    child.sendline(cmd)
    child.expect(PROMPT)
    print(child.before)
</code></pre>

<p>一旦通过验证,我们就可以用上面的command函数在ssh会话中发送命令，然后等待命令提示符的出现，最后将命令的执行结果通过child.before打印出来。</p></li>
<li><p>一个包含参数解析的main函数:</p>

<pre><code class="language-Python">def main():
    parse = optparse.OptionParser(&#39;Usage %prog -H &lt;host&gt; -u &lt;username&gt; -p &lt;password&gt; -c &lt;command&gt;&#39;)
    parse.add_option(&#39;-H&#39;,dest=&#39;host&#39;,type=&#39;string&#39;,help=&#39;specify the host&#39;)
    parse.add_option(&#39;-u&#39;,dest=&#39;username&#39;,type=&#39;string&#39;,help=&#39;specify the username&#39;)
    parse.add_option(&#39;-p&#39;,dest=&#39;password&#39;,type=&#39;string&#39;,help=&#39;specify the password&#39;)    
    parse.add_option(&#39;-c&#39;,dest=&#39;command&#39;,type=&#39;string&#39;,help=&#39;specify the command&#39;)

    (options,args)=parse.parse_args()
    host = options.host
    username = options.username
    password = options.password
    command = options.command

    session = createChildSession(host,username,password)
    send_command(session,command)
</code></pre>

<p>optparse是一个用来给你的代码添加各种命令参数的库，用其解析出输入的host,username,password已经command,然后调用创建session会话，最后利用send_command向此session发送命令</p></li>
</ol>

<pre><code class="language-Bash">tianxianggendeiMac:Python-Study Apple$ python ssh.py -H pi.****.com -u root -p ***** -c pwd
</code></pre>

<p>输出:</p>

<pre><code class="language-Bash"> pwd
/root
root@raspberrypi:~
</code></pre>

<h5 id="toc_2">完整代码</h5>

<pre><code class="language-Python">#!/usr/bin/python
#-*-coding:utf-8-*-
# date:2016-6-21
# author:root
# 利用pexpect模拟ssh登陆

import pexpect
import optparse

PROMPT = [&#39;#&#39;,&#39;$&#39;,&#39;&gt;&#39;,&#39;\$&#39;,&#39;&gt;&gt;&gt;&#39;]

def send_command(child,cmd):
    child.sendline(cmd)
    child.expect(PROMPT)
    print(child.before)

def createChildSession(host,username,password):
    command = &#39;ssh &#39;+username+&#39;@&#39;+host
    child = pexpect.spawn(command)
    ret = child.expect([pexpect.TIMEOUT,&#39;Are you sure you want to continue connecting&#39;,&#39;[P|p]assword&#39;]+PROMPT)
    if ret == 0:
        print(&#39;[-] Error Connecting&#39;)
        return
    if ret == 1:
        child.sendline(&#39;yes&#39;)
        ret = child.expect([pexpect.TIMEOUT,&#39;[p|P]assword&#39;])
        if ret == 0:
            print(&#39;[-] Error Connecting&#39;)
            return
        if ret == 1:
            send_command(password)
            return
    if ret == 2:
        send_command(password)
        return
    return child

def main():
    parse = optparse.OptionParser(&#39;Usage %prog -H &lt;host&gt; -u &lt;username&gt; -p &lt;password&gt; -c &lt;command&gt;&#39;)
    parse.add_option(&#39;-H&#39;,dest=&#39;host&#39;,type=&#39;string&#39;,help=&#39;specify the host&#39;)
    parse.add_option(&#39;-u&#39;,dest=&#39;username&#39;,type=&#39;string&#39;,help=&#39;specify the username&#39;)
    parse.add_option(&#39;-p&#39;,dest=&#39;password&#39;,type=&#39;string&#39;,help=&#39;specify the password&#39;)    
    parse.add_option(&#39;-c&#39;,dest=&#39;command&#39;,type=&#39;string&#39;,help=&#39;specify the command&#39;)

    (options,args)=parse.parse_args()
    host = options.host
    username = options.username
    password = options.password
    command = options.command
    
    session = createChildSession(host,username,password)
    send_command(session,command)

if __name__ == &#39;__main__&#39;:
    main()
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/5/11</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='python.html'>Python</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14945010672564.html">
                
                  <h1>树莓派3安装Node.js</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>(树莓派官方系统)<br/>
<img src="http://pic.mylonly.com/2016-06-29_14634631824044.jpg" alt="2016-06-29_14634631824044.jpg"/></p>

<pre><code class="language-Bash">wget https://nodejs.org/dist/v5.2.0/node-v5.2.0-linux-armv7l.tar.gz
tar zxvf node-v5.2.0-linux-armv7l.tar.gz
cd node-v5.2.0-linux-armv7l
sudo cp bin/* /usr/bin/ -r
sudo cp include/ /usr/include/ -r
sudo cp lib/ /usr/lib/ -r
sudo cp share/ /usr/share/ -r
cd ..
node --version
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/5/11</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='linux.html'>Linux</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14945010588526.html">
                
                  <h1>树莓派3命令行连接WiFi和蓝牙设备</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>转载<a href="https://www.embbnux.com/2016/04/10/raspberry_pi_3_wifi_and_bluetooth_setting_on_console/">原文链接</a></p>

<p><img src="http://pic.mylonly.com/2016-06-29_14634631824044.jpg" alt="2016-06-29_14634631824044.jpg"/></p>

<h3 id="toc_0">WiFi连接</h3>

<pre><code>pi@raspi3:~ $ iwlist scan
wlan0 Scan completed :
Cell 01 - Address: 00:1E:20:50:AA:BB
Channel:8
Frequency:2.447 GHz (Channel 8)
Quality=70/70 Signal level=-32 dBm
Encryption key:on
ESSID:&quot;WIFINAME&quot;
Bit Rates:1 Mb/s; 2 Mb/s; 5.5 Mb/s; 11 Mb/s; 6 Mb/s
9 Mb/s; 12 Mb/s; 18 Mb/s
Bit Rates:24 Mb/s; 36 Mb/s; 48 Mb/s; 54 Mb/s
Mode:Master
Extra:tsf=0000000000000000
Extra: Last beacon: 2157000ms ago
IE: Unknown: 000546616E6379
IE: Unknown: 010882848B960C121824
IE: Unknown: 030108
IE: Unknown: 050401020000
IE: Unknown: 0706303020010B14
IE: Unknown: 2A0100
IE: Unknown: 32043048606C
IE: IEEE 802.11i/WPA2 Version 1
Group Cipher : TKIP
Pairwise Ciphers (2) : CCMP TKIP
Authentication Suites (1) : PSK
IE: Unknown: 7F080000000000000040
IE: Unknown: DD180050F2020101000003A4000027A4000042435E0062322F00
 
可以看到周围的wifi热点信息
配置连接到某个热点:
 
# 编辑wifi文件
sudo vim /etc/wpa_supplicant/wpa_supplicant.conf
# 在该文件最后添加下面的话
network={
  ssid=&quot;WIFINAME&quot;
  psk=&quot;password&quot;
}
# 引号部分分别为wifi的名字和密码
# 保存文件后几秒钟应该就会自动连接到该wifi
# 查看是否连接成功
ifconfig wlan0

</code></pre>

<h3 id="toc_1">蓝牙连接</h3>

<pre><code>pi@raspi3:~ $ sudo bluetoothctl
[NEW] Controller BB:27:EB:0D:9D:DD raspi3 [default]
[bluetooth]# list
Controller BB:27:EB:0D:9D:DD raspi3 [default]
[bluetooth]# power on
Changing power on succeeded
[bluetooth]# scan on
Discovery started
[CHG] Controller BB:27:EB:0D:9D:DD Discovering: yes
[NEW] Device E8:07:BF:3A:25:AA NDZ-03-GA
[CHG] Device E8:07:BF:3A:25:AA RSSI: -66
[bluetooth]# agent on
Agent registered
[CHG] Device E8:07:BF:3A:25:AA RSSI: -56
[bluetooth]# pair E8:07:BF:3A:25:AA
Attempting to pair with E8:07:BF:3A:25:AA
[CHG] Device E8:07:BF:3A:25:AA Connected: yes
[CHG] Device E8:07:BF:3A:25:AA UUIDs:
    00001108-0000-1000-8000-00805f9b34ff
[CHG] Device E8:07:BF:3A:25:AA Paired: yes
Pairing successful
[CHG] Device E8:07:BF:3A:25:AA Connected: no
[bluetooth]# trust E8:07:BF:3A:25:AA
[CHG] Device E8:07:BF:3A:25:AA Trusted: yes
Changing E8:07:BF:3A:25:AA trust succeeded
[bluetooth]# connect E8:07:BF:3A:25:AA

</code></pre>

<p>这样就连上蓝牙设备了，如果是蓝牙音响的话还得装下支持软件:<br/>
 <code><br/>
sudo apt-get install pulseaudio pulseaudio-module-bluetooth<br/>
</code></p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/5/11</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='linux.html'>Linux</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="14945010480752.html">
                
                  <h1>各种程序的安装</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<ol>
<li>源码安装nginx</li>
</ol>

<pre><code>#安装编译nginx必须的依赖
yum install gcc-c++
yum install pcre pcre-devel  
yum install zlib zlib-devel 
yum install openssl openssl--devel

#下载nginx源码
wget http://nginx.org/download/nginx-1.9.15.tar.gz

#解压
tar -zvxf nginx-1.9.15.tar.gz -C ../document/

#编译安装
cd ../document/nginx-1.9.15
./configure
make
make install
</code></pre>

<ol>
<li>setuptools 安装</li>
</ol>

<pre><code>wget https://bootstrap.pypa.io/ez_setup.py -O - | python

</code></pre>

<ol>
<li>pip源码安装</li>
</ol>

<pre><code>[pip官网安装](https://pypi.python.org/pypi/pip)
</code></pre>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/5/11</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='linux.html'>Linux</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   <a href="all.html">&laquo; Prev Page</a>  
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			 <a href="all_2.html">&raquo; Next Page</a> 
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="http://pic.mylonly.com/2017-05-11-IMG_1164.JPG" /></div>
            
                <h1>独自一人</h1>
                <div class="site-des">独自一人,独自Coding...</div>
                <div class="social">









<a target="_blank" class="github" target="_blank" href="http://github.com/mylonly" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:root@mylonly.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="ios.html"><strong>iOS</strong></a>
        
            <a href="linux.html"><strong>Linux</strong></a>
        
            <a href="python.html"><strong>Python</strong></a>
        
            <a href="tools.html"><strong>Tools</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="14945011765615.html">VSCode1.0更换回英文版本</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14945011548149.html">简单Scrapy爬虫</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14945011465578.html">利用pxssh暴力破解ssh密码</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14945011328774.html">Scrapy模拟登陆知乎</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="14945011244738.html">Scrapy抓取Ajax动态页面</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    



  </body>
</html>
